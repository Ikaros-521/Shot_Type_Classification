# é•œå¤´ç±»å‹åˆ†ç±» - è®­ç»ƒæŒ‡å—
æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä»å¤´å¼€å§‹è®­ç»ƒé•œå¤´ç±»å‹åˆ†ç±»æ¨¡å‹ã€‚

## ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
2. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
3. [æ¨¡å‹è®­ç»ƒ](#æ¨¡å‹è®­ç»ƒ)
4. [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
5. [è°ƒä¼˜æŠ€å·§](#è°ƒä¼˜æŠ€å·§)
6. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ç¯å¢ƒå‡†å¤‡

### 1. ç³»ç»Ÿè¦æ±‚

- Python 3.7+
- CUDA 10.2+ (å¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿ)
- è‡³å°‘8GBå†…å­˜
- è‡³å°‘20GBå¯ç”¨ç£ç›˜ç©ºé—´

### 2. å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv shot_classification_env
source shot_classification_env/bin/activate  # Linux/Mac
# shot_classification_env\Scripts\activate  # Windows

# å®‰è£…PyTorch (æ ¹æ®ä½ çš„CUDAç‰ˆæœ¬é€‰æ‹©)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install pandas numpy matplotlib seaborn scikit-learn pillow opencv-python tqdm
```

### 3. ä¸‹è½½MovieShotsæ•°æ®é›†

ä»ä»¥ä¸‹ç½‘å€ä¸‹è½½MovieShotsæ•°æ®é›†ï¼š
- https://paperswithcode.com/dataset/movieshots
- https://arxiv.org/abs/2008.03548

ä¸‹è½½åï¼Œå°†æ•°æ®é›†æ–‡ä»¶ç»„ç»‡å¦‚ä¸‹ï¼š

```
data/
â”œâ”€â”€ v1_full_trailer.json          # æ ‡æ³¨æ–‡ä»¶
â””â”€â”€ trailer/                      # è§†é¢‘æ–‡ä»¶
    â”œâ”€â”€ tt0012345/                # ç”µå½±æ–‡ä»¶å¤¹
    â”‚   â”œâ”€â”€ shot_0001.mp4
    â”‚   â”œâ”€â”€ shot_0002.mp4
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...
```

## æ•°æ®å‡†å¤‡

### 1. è‡ªåŠ¨åŒ–æ•°æ®å‡†å¤‡

ä½¿ç”¨æˆ‘ä»¬æä¾›çš„è‡ªåŠ¨åŒ–è„šæœ¬ï¼š

```bash
# æ‰§è¡Œå®Œæ•´çš„æ•°æ®å‡†å¤‡æµç¨‹
python prepare_data.py --data-dir ./data --full-process

# æˆ–è€…åˆ†æ­¥éª¤æ‰§è¡Œ
python prepare_data.py --data-dir ./data --parse-json
python prepare_data.py --data-dir ./data --organize-videos  
python prepare_data.py --data-dir ./data --extract-frames
python prepare_data.py --data-dir ./data --split-data
```

### 2. æ‰‹åŠ¨æ•°æ®å‡†å¤‡

å¦‚æœä½ æƒ³æ‰‹åŠ¨æ§åˆ¶æ¯ä¸ªæ­¥éª¤ï¼š

#### æ­¥éª¤1: è§£æJSONæ ‡ç­¾
```bash
python prepare_data.py --data-dir ./data --parse-json
```

è¿™ä¼šç”Ÿæˆ `dataset.csv` æ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰è§†é¢‘çš„æ ‡ç­¾ä¿¡æ¯ã€‚

#### æ­¥éª¤2: ç»„ç»‡è§†é¢‘æ–‡ä»¶
```bash
python prepare_data.py --data-dir ./data --organize-videos
```

å°†è§†é¢‘æŒ‰ç±»åˆ«ç»„ç»‡åˆ°ä¸åŒæ–‡ä»¶å¤¹ï¼š
```
data/categorized/
â”œâ”€â”€ CS/     # ç‰¹å†™é•œå¤´
â”œâ”€â”€ ECS/    # æç‰¹å†™é•œå¤´
â”œâ”€â”€ FS/     # å…¨æ™¯é•œå¤´
â”œâ”€â”€ LS/     # è¿œæ™¯é•œå¤´
â””â”€â”€ MS/     # ä¸­æ™¯é•œå¤´
```

#### æ­¥éª¤3: æå–è§†é¢‘å¸§
```bash
# é»˜è®¤æ¯25å¸§æå–ä¸€å¸§
python prepare_data.py --data-dir ./data --extract-frames

# è‡ªå®šä¹‰å¸§é—´éš”
python prepare_data.py --data-dir ./data --extract-frames --frame-interval 30
```

#### æ­¥éª¤4: åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
```bash
# é»˜è®¤20%ä½œä¸ºæµ‹è¯•é›†
python prepare_data.py --data-dir ./data --split-data

# è‡ªå®šä¹‰æµ‹è¯•é›†æ¯”ä¾‹
python prepare_data.py --data-dir ./data --split-data --test-ratio 0.3
```

### 3. æ•°æ®ç»“æ„è¯´æ˜

æœ€ç»ˆçš„æ•°æ®ç»“æ„å¦‚ä¸‹ï¼š

```
data/frames/
â”œâ”€â”€ training/                    # è®­ç»ƒé›† (80%)
â”‚   â”œâ”€â”€ CS/                     # ç‰¹å†™é•œå¤´
â”‚   â”œâ”€â”€ ECS/                    # æç‰¹å†™é•œå¤´
â”‚   â”œâ”€â”€ FS/                     # å…¨æ™¯é•œå¤´
â”‚   â”œâ”€â”€ LS/                     # è¿œæ™¯é•œå¤´
â”‚   â””â”€â”€ MS/                     # ä¸­æ™¯é•œå¤´
â””â”€â”€ testing/                     # æµ‹è¯•é›† (20%)
    â”œâ”€â”€ CS/
    â”œâ”€â”€ ECS/
    â”œâ”€â”€ FS/
    â”œâ”€â”€ LS/
    â””â”€â”€ MS/
```

## æ¨¡å‹è®­ç»ƒ

### 1. åŸºç¡€è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒå‘½ä»¤
python train.py --data-dir ./data/frames/training

# æŒ‡å®šè®­ç»ƒè½®æ•°å’Œæ‰¹æ¬¡å¤§å°
python train.py --data-dir ./data/frames/training --epochs 100 --batch-size 32

# è‡ªå®šä¹‰å­¦ä¹ ç‡
python train.py --data-dir ./data/frames/training --lr 0.0005
```

### 2. é«˜çº§è®­ç»ƒé€‰é¡¹

```bash
# å®Œæ•´å‚æ•°ç¤ºä¾‹
python train.py \
    --data-dir ./data/frames/training \
    --epochs 50 \
    --batch-size 16 \
    --lr 0.001 \
    --val-split 0.2 \
    --model-name shot_classifier_v1 \
    --output-dir ./models
```

### 3. è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--data-dir` | å¿…éœ€ | è®­ç»ƒæ•°æ®ç›®å½• |
| `--epochs` | 50 | è®­ç»ƒè½®æ•° |
| `--batch-size` | 16 | æ‰¹æ¬¡å¤§å° |
| `--lr` | 0.001 | å­¦ä¹ ç‡ |
| `--val-split` | 0.2 | éªŒè¯é›†æ¯”ä¾‹ |
| `--model-name` | æ—¶é—´æˆ³ | æ¨¡å‹ä¿å­˜åç§° |
| `--output-dir` | ./models | æ¨¡å‹è¾“å‡ºç›®å½• |

### 4. è®­ç»ƒè¿‡ç¨‹ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š

```
Epoch 1/50 [è®­ç»ƒ]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245/245 [02:15<00:00, Loss: 0.8234, Acc: 0.7123]
Epoch 1/50 [éªŒè¯]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:15<00:00, Loss: 0.6234, Acc: 0.8456]
Epoch 1/50 (150.2s) - Train Loss: 0.8234, Train Acc: 0.7123, Val Loss: 0.6234, Val Acc: 0.8456
```

## æ¨¡å‹è¯„ä¼°

### 1. è‡ªåŠ¨è¯„ä¼°

è®­ç»ƒå®Œæˆåä¼šè‡ªåŠ¨ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šï¼š

```
ğŸ“ˆ åˆ†ç±»æŠ¥å‘Š:
  æç‰¹å†™ (Extreme close-up shot):
    ç²¾ç¡®ç‡: 0.9234, å¬å›ç‡: 0.9123, F1åˆ†æ•°: 0.9178
  ç‰¹å†™ (Close-up shot):
    ç²¾ç¡®ç‡: 0.8956, å¬å›ç‡: 0.9345, F1åˆ†æ•°: 0.9146
  ...
  æ€»ä½“å‡†ç¡®ç‡: 0.9123
```

### 2. å¯è§†åŒ–ç»“æœ

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆï¼š

- **è®­ç»ƒå†å²å›¾**: æ˜¾ç¤ºæŸå¤±å’Œå‡†ç¡®ç‡çš„å˜åŒ–
- **æ··æ·†çŸ©é˜µ**: æ˜¾ç¤ºå„ç±»åˆ«çš„é¢„æµ‹æ€§èƒ½

### 3. æ¨¡å‹æ–‡ä»¶

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
models/
â”œâ”€â”€ shot_classifier_20231215_143022.pt           # æ¨¡å‹æƒé‡
â”œâ”€â”€ shot_classifier_20231215_143022_history.pth  # è®­ç»ƒå†å²
â””â”€â”€ shot_classifier_20231215_143022_report.json  # è¯„ä¼°æŠ¥å‘Š
```

## è°ƒä¼˜æŠ€å·§

### 1. è¶…å‚æ•°è°ƒä¼˜

#### å­¦ä¹ ç‡è°ƒæ•´
```bash
# è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œæ›´ç¨³å®š
python train.py --data-dir ./data/frames/training --lr 0.0001

# ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦
python train.py --data-dir ./data/frames/training --lr 0.01
```

#### æ‰¹æ¬¡å¤§å°è°ƒæ•´
```bash
# å¤§æ‰¹æ¬¡å¤§å°ï¼ˆéœ€è¦æ›´å¤šå†…å­˜ï¼‰
python train.py --data-dir ./data/frames/training --batch-size 32

# å°æ‰¹æ¬¡å¤§å°ï¼ˆå†…å­˜è¾ƒå°‘æ—¶ï¼‰
python train.py --data-dir ./data/frames/training --batch-size 8
```

#### è®­ç»ƒè½®æ•°
```bash
# æ›´å¤šçš„è®­ç»ƒè½®æ•°
python train.py --data-dir ./data/frames/training --epochs 100

# æ—©åœæœºåˆ¶ï¼ˆè§‚å¯ŸéªŒè¯æŸå¤±ï¼‰
python train.py --data-dir ./data/frames/training --epochs 200
```

### 2. æ•°æ®å¢å¼ºè°ƒæ•´

åœ¨ `train.py` ä¸­çš„ `get_data_transforms()` å‡½æ•°ä¸­è°ƒæ•´ï¼š

```python
# å¢å¼ºæ•°æ®å¢å¼º
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),           # æ°´å¹³ç¿»è½¬
    transforms.RandomRotation(degrees=15),            # æ—‹è½¬
    transforms.ColorJitter(brightness=0.3,            # äº®åº¦è°ƒæ•´
                          contrast=0.3,              # å¯¹æ¯”åº¦è°ƒæ•´
                          saturation=0.3,             # é¥±å’Œåº¦è°ƒæ•´
                          hue=0.1),                  # è‰²è°ƒè°ƒæ•´
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), # éšæœºè£å‰ª
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                       std=[0.229, 0.224, 0.225])
])
```

### 3. æ¨¡å‹æ¶æ„è°ƒæ•´

#### æ›´æ¢åŸºç¡€æ¨¡å‹
```python
# åœ¨ create_model() å‡½æ•°ä¸­
# ä½¿ç”¨ä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹
model = models.resnet50(pretrained=True)           # ResNet-50
model = models.efficientnet_b0(pretrained=True)    # EfficientNet-B0
model = models.vgg16(pretrained=True)               # VGG-16

# ä¿®æ”¹åˆ†ç±»å™¨
if hasattr(model, 'fc'):  # ResNet
    model.fc = nn.Linear(model.fc.in_features, num_classes)
elif hasattr(model, 'classifier'):  # VGG, MobileNet
    if isinstance(model.classifier, nn.Sequential):
        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)
```

### 4. æ­£åˆ™åŒ–æŠ€æœ¯

#### Dropoutè°ƒæ•´
```python
# åœ¨æ¨¡å‹ä¸­æ·»åŠ dropout
model.classifier = nn.Sequential(
    nn.Linear(model.classifier[0].in_features, 1280),
    nn.Hardswish(),
    nn.Dropout(p=0.3),  # è°ƒæ•´dropoutç‡
    nn.Linear(1280, num_classes)
)
```

#### æƒé‡è¡°å‡
```python
# åœ¨è®­ç»ƒå‘½ä»¤ä¸­è°ƒæ•´
optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-3)  # å¢åŠ æƒé‡è¡°å‡
```

## æ•…éšœæ’é™¤

### 1. å¸¸è§é”™è¯¯

#### CUDAå†…å­˜ä¸è¶³
```
RuntimeError: CUDA out of memory
```
**è§£å†³æ–¹æ¡ˆ:**
- å‡å°æ‰¹æ¬¡å¤§å°: `--batch-size 8`
- ä½¿ç”¨CPUè®­ç»ƒ: è®¾ç½® `device = 'cpu'`
- æ¸…ç†GPUç¼“å­˜: `torch.cuda.empty_cache()`

#### æ•°æ®ç›®å½•ä¸å­˜åœ¨
```
âœ— æ•°æ®ç›®å½•ä¸å­˜åœ¨: ./data/frames/training
```
**è§£å†³æ–¹æ¡ˆ:**
- ç¡®ä¿å·²å®Œæˆæ•°æ®å‡†å¤‡: `python prepare_data.py --full-process`
- æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®

#### å›¾åƒåŠ è½½å¤±è´¥
```
âœ— å›¾åƒå¤„ç†å¤±è´¥: cannot identify image file
```
**è§£å†³æ–¹æ¡ˆ:**
- æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦æŸå
- ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®ï¼ˆJPGã€PNGï¼‰
- é‡æ–°æå–è§†é¢‘å¸§

### 2. æ€§èƒ½é—®é¢˜

#### è®­ç»ƒé€Ÿåº¦æ…¢
**å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ¡ˆ:**
- **CPUè®­ç»ƒ**: ä½¿ç”¨GPUåŠ é€Ÿ
- **æ‰¹æ¬¡å¤§å°è¿‡å°**: é€‚å½“å¢åŠ æ‰¹æ¬¡å¤§å°
- **æ•°æ®åŠ è½½ç“¶é¢ˆ**: å¢åŠ  `num_workers` å‚æ•°
- **å›¾åƒè¿‡å¤§**: è°ƒæ•´å›¾åƒå°ºå¯¸

#### è¿‡æ‹Ÿåˆ
**è¡¨ç°:**
- è®­ç»ƒå‡†ç¡®ç‡é«˜ï¼ŒéªŒè¯å‡†ç¡®ç‡ä½
- è®­ç»ƒæŸå¤±æŒç»­ä¸‹é™ï¼ŒéªŒè¯æŸå¤±å¼€å§‹ä¸Šå‡

**è§£å†³æ–¹æ¡ˆ:**
- å¢åŠ æ•°æ®å¢å¼º
- ä½¿ç”¨dropout
- å¢åŠ æƒé‡è¡°å‡
- å‡å°‘æ¨¡å‹å¤æ‚åº¦
- å¢åŠ è®­ç»ƒæ•°æ®

#### æ¬ æ‹Ÿåˆ
**è¡¨ç°:**
- è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡éƒ½è¾ƒä½
- æŸå¤±å€¼è¾ƒé«˜ä¸”ä¸ä¸‹é™

**è§£å†³æ–¹æ¡ˆ:**
- å¢åŠ æ¨¡å‹å¤æ‚åº¦
- å‡å°‘æ­£åˆ™åŒ–
- å¢åŠ è®­ç»ƒè½®æ•°
- è°ƒæ•´å­¦ä¹ ç‡

### 3. è°ƒè¯•æŠ€å·§

#### æ£€æŸ¥æ•°æ®åŠ è½½
```python
# æ·»åŠ åˆ°è®­ç»ƒè„šæœ¬ä¸­è°ƒè¯•
dataset = ShotDataset(args.data_dir, train_transform)
print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
print(f"ç±»åˆ«åˆ†å¸ƒ: {[sum(1 for _, label in dataset if label == i) for i in range(5)]}")

# æ£€æŸ¥å•ä¸ªæ ·æœ¬
image, label = dataset[0]
print(f"å›¾åƒå½¢çŠ¶: {image.shape}")
print(f"æ ‡ç­¾: {label}")
```

#### å¯è§†åŒ–æ•°æ®
```python
import matplotlib.pyplot as plt

# æ˜¾ç¤ºä¸€äº›è®­ç»ƒæ ·æœ¬
def show_samples(dataset, num_samples=6):
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    for i, (image, label) in enumerate(dataset):
        if i >= num_samples:
            break
        ax = axes[i//3, i%3]
        # åå½’ä¸€åŒ–
        image = image * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
        image = image + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        image = torch.clamp(image, 0, 1)
        ax.imshow(image.permute(1, 2, 0))
        ax.set_title(f'Class: {CLASS_NAMES[label]}')
        ax.axis('off')
    plt.show()

show_samples(train_dataset)
```

## æœ€ä½³å®è·µ

### 1. å®éªŒç®¡ç†
- ä¸ºæ¯æ¬¡å®éªŒä½¿ç”¨ä¸åŒçš„æ¨¡å‹åç§°
- ä¿å­˜è®­ç»ƒå†å²å’Œè¶…å‚æ•°
- ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†ä»£ç 

### 2. æ¨¡å‹é€‰æ‹©
- åŸºäºéªŒè¯é›†å‡†ç¡®ç‡é€‰æ‹©æœ€ä½³æ¨¡å‹
- è€ƒè™‘æ¨¡å‹å¤§å°å’Œæ¨ç†é€Ÿåº¦çš„å¹³è¡¡
- ä¿å­˜å¤šä¸ªæ£€æŸ¥ç‚¹ä»¥å¤‡åç”¨

### 3. æŒç»­æ”¹è¿›
- å®šæœŸé‡æ–°è¯„ä¼°æ¨¡å‹æ€§èƒ½
- æ ¹æ®æ–°æ•°æ®æ›´æ–°æ¨¡å‹
- å°è¯•ä¸åŒçš„æ¶æ„å’ŒæŠ€æœ¯

## è¿›é˜¶ä¸»é¢˜

### 1. è¿ç§»å­¦ä¹ 
```python
# ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œç‰¹å¾æå–
model = models.mobilenet_v3_large(pretrained=True)
for param in model.parameters():
    param.requires_grad = False  # å†»ç»“ç‰¹å¾æå–å±‚

# åªè®­ç»ƒåˆ†ç±»å™¨
model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)
```

### 2. é›†æˆå­¦ä¹ 
```python
# è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶é›†æˆé¢„æµ‹
models_ensemble = [create_model() for _ in range(5)]
# ... è®­ç»ƒæ¯ä¸ªæ¨¡å‹ ...

def ensemble_predict(models, input):
    outputs = [model(input) for model in models]
    avg_output = torch.mean(torch.stack(outputs), dim=0)
    return avg_output
```

### 3. è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–
ä½¿ç”¨Optunaç­‰å·¥å…·è¿›è¡Œè‡ªåŠ¨è¶…å‚æ•°æœç´¢ï¼š

```python
import optuna

def objective(trial):
    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)
    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])
    # ... è®­ç»ƒæ¨¡å‹å¹¶è¿”å›éªŒè¯å‡†ç¡®ç‡ ...
    return validation_accuracy

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)
```

## æ€»ç»“

é€šè¿‡æœ¬æŒ‡å—ï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

1. âœ… å‡†å¤‡MovieShotsæ•°æ®é›†
2. âœ… è®­ç»ƒé«˜æ€§èƒ½çš„é•œå¤´åˆ†ç±»æ¨¡å‹
3. âœ… è¯„ä¼°å’Œä¼˜åŒ–æ¨¡å‹æ€§èƒ½
4. âœ… è§£å†³å¸¸è§è®­ç»ƒé—®é¢˜

è®°ä½ï¼Œæ·±åº¦å­¦ä¹ æ˜¯ä¸€ä¸ªè¿­ä»£çš„è¿‡ç¨‹ã€‚ä¸æ–­å®éªŒã€è°ƒæ•´å’Œæ”¹è¿›æ˜¯è·å¾—æœ€ä½³ç»“æœçš„å…³é”®ã€‚
