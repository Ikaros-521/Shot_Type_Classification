#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é•œå¤´ç±»å‹åˆ†ç±»æ¨¡å‹è®­ç»ƒè„šæœ¬
åŸºäºPyTorchçš„æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ
"""
import os
import sys
import argparse
import time
import warnings
from datetime import datetime

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import torchvision
from torchvision import datasets, transforms, models
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from tqdm import tqdm

warnings.simplefilter("ignore")

# è®¾å¤‡é…ç½®
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# ç±»åˆ«æ˜ å°„
CLASS_NAMES = ['ECS', 'CS', 'FS', 'LS', 'MS']  # æŒ‰å­—æ¯é¡ºåºæ’åº
CLASS_MAPPING = {
    'ECS': 'æç‰¹å†™ (Extreme close-up shot)',
    'CS': 'ç‰¹å†™ (Close-up shot)', 
    'FS': 'å…¨æ™¯ (Full shot)',
    'LS': 'è¿œæ™¯ (Long shot)',
    'MS': 'ä¸­æ™¯ (Medium shot)'
}

class ShotDataset(torch.utils.data.Dataset):
    """è‡ªå®šä¹‰æ•°æ®é›†ç±»"""
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.images = []
        self.labels = []
        
        # åŠ è½½æ•°æ®
        for class_idx, class_name in enumerate(CLASS_NAMES):
            class_dir = os.path.join(data_dir, class_name)
            if os.path.exists(class_dir):
                for img_name in os.listdir(class_dir):
                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                        self.images.append(os.path.join(class_dir, img_name))
                        self.labels.append(class_idx)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]
        
        if self.transform:
            image = self.transform(image)
            
        return image, label

def get_data_transforms():
    """è·å–æ•°æ®é¢„å¤„ç†å˜æ¢"""
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    return train_transform, val_transform

def create_model(num_classes=5):
    """åˆ›å»ºæ¨¡å‹æ¶æ„"""
    # ä½¿ç”¨MobileNetV3ä½œä¸ºåŸºç¡€æ¨¡å‹
    model = models.mobilenet_v3_large(pretrained=True)
    
    # ä¿®æ”¹åˆ†ç±»å™¨
    model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)
    
    return model

def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, scheduler=None):
    """è®­ç»ƒæ¨¡å‹"""
    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []
    
    best_val_acc = 0.0
    best_model_state = None
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch")
    print("-" * 50)
    
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        running_loss = 0.0
        running_corrects = 0
        
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [è®­ç»ƒ]')
        
        for inputs, labels in train_pbar:
            inputs = inputs.to(device)
            labels = labels.to(device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # ç»Ÿè®¡
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            running_corrects += torch.sum(preds == labels.data)
            
            # æ›´æ–°è¿›åº¦æ¡
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{running_corrects.double() / (train_pbar.n * train_loader.batch_size):.4f}'
            })
        
        epoch_train_loss = running_loss / len(train_loader.dataset)
        epoch_train_acc = running_corrects.double() / len(train_loader.dataset)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_corrects = 0
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [éªŒè¯]')
            
            for inputs, labels in val_pbar:
                inputs = inputs.to(device)
                labels = labels.to(device)
                
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)
                val_corrects += torch.sum(preds == labels.data)
                
                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{val_corrects.double() / (val_pbar.n * val_loader.batch_size):.4f}'
                })
        
        epoch_val_loss = val_loss / len(val_loader.dataset)
        epoch_val_acc = val_corrects.double() / len(val_loader.dataset)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        if scheduler:
            scheduler.step()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if epoch_val_acc > best_val_acc:
            best_val_acc = epoch_val_acc
            best_model_state = model.state_dict()
        
        # è®°å½•å†å²
        train_losses.append(epoch_train_loss)
        val_losses.append(epoch_val_loss)
        train_accs.append(epoch_train_acc.item())
        val_accs.append(epoch_val_acc.item())
        
        # æ‰“å°epochç»“æœ
        epoch_time = time.time() - epoch_start_time
        print(f'Epoch {epoch+1}/{num_epochs} ({epoch_time:.1f}s) - '
              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, '
              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}')
        
        if (epoch + 1) % 10 == 0:
            print(f'æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}')
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_state:
        model.load_state_dict(best_model_state)
    
    history = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_accs': train_accs,
        'val_accs': val_accs
    }
    
    return model, history

def evaluate_model(model, test_loader, class_names):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    all_preds = []
    all_labels = []
    
    print("æ­£åœ¨è¯„ä¼°æ¨¡å‹...")
    with torch.no_grad():
        for inputs, labels in tqdm(test_loader, desc='è¯„ä¼°ä¸­'):
            inputs = inputs.to(device)
            labels = labels.to(device)
            
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
    report = classification_report(all_labels, all_preds, 
                                  target_names=class_names,
                                  output_dict=True)
    
    # ç”Ÿæˆæ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    
    return report, cm, all_preds, all_labels

def plot_training_history(history, save_path=None):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # æŸå¤±æ›²çº¿
    ax1.plot(history['train_losses'], label='è®­ç»ƒæŸå¤±', color='blue')
    ax1.plot(history['val_losses'], label='éªŒè¯æŸå¤±', color='red')
    ax1.set_title('æ¨¡å‹æŸå¤±')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('æŸå¤±')
    ax1.legend()
    ax1.grid(True)
    
    # å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(history['train_accs'], label='è®­ç»ƒå‡†ç¡®ç‡', color='blue')
    ax2.plot(history['val_accs'], label='éªŒè¯å‡†ç¡®ç‡', color='red')
    ax2.set_title('æ¨¡å‹å‡†ç¡®ç‡')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('å‡†ç¡®ç‡')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"è®­ç»ƒå†å²å›¾å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()

def plot_confusion_matrix(cm, class_names, save_path=None):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    plt.figure(figsize=(10, 8))
    
    # è½¬æ¢ä¸ºä¸­æ–‡ç±»åˆ«åç§°
    chinese_names = [CLASS_MAPPING[name] for name in class_names]
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=chinese_names,
                yticklabels=chinese_names)
    
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.xlabel('é¢„æµ‹ç±»åˆ«')
    plt.ylabel('çœŸå®ç±»åˆ«')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()

def save_model(model, save_path, history=None, evaluation_report=None):
    """ä¿å­˜æ¨¡å‹å’Œç›¸å…³ä¿¡æ¯"""
    torch.save(model.state_dict(), save_path)
    print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    # ä¿å­˜è®­ç»ƒå†å²
    if history:
        history_path = save_path.replace('.pt', '_history.pth')
        torch.save(history, history_path)
        print(f"è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_path}")
    
    # ä¿å­˜è¯„ä¼°æŠ¥å‘Š
    if evaluation_report:
        import json
        report_path = save_path.replace('.pt', '_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(evaluation_report, f, ensure_ascii=False, indent=2)
        print(f"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

def main():
    parser = argparse.ArgumentParser(
        description='é•œå¤´ç±»å‹åˆ†ç±»æ¨¡å‹è®­ç»ƒ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python train.py --data-dir ./data/frames/training
  python train.py --data-dir ./data/frames/training --epochs 100 --batch-size 32
  python train.py --data-dir ./data/frames/training --lr 0.001 --model-name my_model
        """
    )
    
    parser.add_argument('--data-dir', 
                       required=True,
                       help='è®­ç»ƒæ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--epochs', 
                       type=int, 
                       default=50,
                       help='è®­ç»ƒè½®æ•° (é»˜è®¤: 50)')
    parser.add_argument('--batch-size', 
                       type=int, 
                       default=16,
                       help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 16)')
    parser.add_argument('--lr', 
                       type=float, 
                       default=0.001,
                       help='å­¦ä¹ ç‡ (é»˜è®¤: 0.001)')
    parser.add_argument('--val-split', 
                       type=float, 
                       default=0.2,
                       help='éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.2)')
    parser.add_argument('--model-name',
                       default=f'shot_classifier_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
                       help='æ¨¡å‹ä¿å­˜åç§°')
    parser.add_argument('--output-dir',
                       default='./models',
                       help='æ¨¡å‹è¾“å‡ºç›®å½• (é»˜è®¤: ./models)')
    parser.add_argument('--no-save',
                       action='store_true',
                       help='ä¸ä¿å­˜æ¨¡å‹')
    parser.add_argument('--no-plot',
                       action='store_true',
                       help='ä¸æ˜¾ç¤ºå›¾è¡¨')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not os.path.exists(args.data_dir):
        print(f"âœ— æ•°æ®ç›®å½•ä¸å­˜åœ¨: {args.data_dir}")
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒé•œå¤´ç±»å‹åˆ†ç±»æ¨¡å‹")
    print(f"ğŸ“ æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"ğŸ¯ è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"ğŸ“ˆ å­¦ä¹ ç‡: {args.lr}")
    print(f"ğŸ”¢ éªŒè¯é›†æ¯”ä¾‹: {args.val_split}")
    print("-" * 50)
    
    # è·å–æ•°æ®å˜æ¢
    train_transform, val_transform = get_data_transforms()
    
    # åˆ›å»ºæ•°æ®é›†
    full_dataset = ShotDataset(args.data_dir, train_transform)
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(full_dataset)}")
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    val_size = int(len(full_dataset) * args.val_split)
    train_size = len(full_dataset) - val_size
    
    train_dataset, val_dataset = random_split(
        full_dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    # ä¸ºéªŒè¯é›†è®¾ç½®æ­£ç¡®çš„å˜æ¢
    val_dataset.dataset.transform = val_transform
    
    print(f"ğŸ“š è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"ğŸ§ª éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, 
                             batch_size=args.batch_size, 
                             shuffle=True, 
                             num_workers=4)
    val_loader = DataLoader(val_dataset, 
                           batch_size=args.batch_size, 
                           shuffle=False, 
                           num_workers=4)
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(len(CLASS_NAMES))
    model = model.to(device)
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)
    
    # å¼€å§‹è®­ç»ƒ
    start_time = time.time()
    trained_model, history = train_model(
        model, train_loader, val_loader, 
        criterion, optimizer, args.epochs, scheduler
    )
    training_time = time.time() - start_time
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶: {training_time/60:.2f} åˆ†é’Ÿ")
    
    # è¯„ä¼°æ¨¡å‹
    print("\nğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    val_loader_for_eval = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)
    report, cm, preds, labels = evaluate_model(trained_model, val_loader_for_eval, CLASS_NAMES)
    
    # æ‰“å°è¯„ä¼°ç»“æœ
    print("\nğŸ“ˆ åˆ†ç±»æŠ¥å‘Š:")
    for class_name in CLASS_NAMES:
        chinese_name = CLASS_MAPPING[class_name]
        precision = report[class_name]['precision']
        recall = report[class_name]['recall']
        f1 = report[class_name]['f1-score']
        print(f"  {chinese_name}:")
        print(f"    ç²¾ç¡®ç‡: {precision:.4f}, å¬å›ç‡: {recall:.4f}, F1åˆ†æ•°: {f1:.4f}")
    
    print(f"  æ€»ä½“å‡†ç¡®ç‡: {report['accuracy']:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    if not args.no_save:
        model_path = os.path.join(args.output_dir, f"{args.model_name}.pt")
        save_model(trained_model, model_path, history, report)
    
    # ç»˜åˆ¶å›¾è¡¨
    if not args.no_plot:
        plot_training_history(history)
        plot_confusion_matrix(cm, CLASS_NAMES)

if __name__ == "__main__":
    main()
