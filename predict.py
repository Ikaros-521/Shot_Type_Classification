#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é•œå¤´ç±»å‹åˆ†ç±»é¢„æµ‹è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„PyTorchæ¨¡å‹å¯¹å›¾åƒè¿›è¡Œé•œå¤´ç±»å‹åˆ†ç±»
"""
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import argparse
import os
import sys
import time

# ç±»åˆ«æ˜ å°„
CLASS_MAPPING = {
    0: "è¿œæ™¯ (Long shot, LS)",
    1: "å…¨æ™¯ (Full shot, FS)", 
    2: "ä¸­æ™¯ (Medium shot, MS)",
    3: "ç‰¹å†™ (Close-up shot, CS)",
    4: "æç‰¹å†™ (Extreme close-up shot, ECS)"
}

def load_model(model_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    try:
        model = torch.load(model_path, map_location=device)
        model.eval()
        print(f"âœ“ æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
        return model
    except Exception as e:
        print(f"âœ— åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        sys.exit(1)

def preprocess_image(image_path):
    """å›¾åƒé¢„å¤„ç†"""
    try:
        # å›¾åƒé¢„å¤„ç†å˜æ¢
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # åŠ è½½å¹¶è½¬æ¢å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0)
        return image_tensor
    except Exception as e:
        print(f"âœ— å›¾åƒå¤„ç†å¤±è´¥: {e}")
        return None

def predict(image_path, model, device):
    """è¿›è¡Œé¢„æµ‹"""
    # é¢„å¤„ç†å›¾åƒ
    image_tensor = preprocess_image(image_path)
    if image_tensor is None:
        return None
    
    # ç§»åŠ¨åˆ°è®¾å¤‡
    image_tensor = image_tensor.to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        start_time = time.time()
        outputs = model(image_tensor)
        probabilities = torch.softmax(outputs, dim=1)
        confidence, predicted = torch.max(probabilities, 1)

        print(f"âœ“ é¢„æµ‹å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.4f} ç§’")
        
        return {
            'class_id': predicted.item(),
            'class_name': CLASS_MAPPING[predicted.item()],
            'confidence': confidence.item()
        }

def main():
    parser = argparse.ArgumentParser(
        description='é•œå¤´ç±»å‹åˆ†ç±»é¢„æµ‹å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python predict.py image.jpg                    # é¢„æµ‹å•å¼ å›¾åƒ
  python predict.py image.jpg --verbose          # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  python predict.py image.jpg --model custom.pt  # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
        """
    )
    
    parser.add_argument('image_path', 
                       help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--model', 
                       default='./models/Pytorch_Classification_50ep.pt',
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./models/Pytorch_Classification_50ep.pt)')
    parser.add_argument('--verbose', '-v',
                       action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†é¢„æµ‹ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.image_path):
        print(f"âœ— å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {args.image_path}")
        sys.exit(1)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model):
        print(f"âœ— æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        sys.exit(1)
    
    # è®¾ç½®è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    model = load_model(args.model, device)
    
    # è¿›è¡Œé¢„æµ‹
    print(f"æ­£åœ¨å¤„ç†å›¾åƒ: {args.image_path}")
    result = predict(args.image_path, model, device)
    
    if result:
        print(f"\nğŸ¯ é¢„æµ‹ç»“æœ:")
        print(f"   ç±»åˆ«: {result['class_name']}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.4f} ({result['confidence']*100:.2f}%)")
        
        if args.verbose:
            print(f"\nğŸ“Š è¯¦ç»†ä¿¡æ¯:")
            print(f"   ç±»åˆ«ID: {result['class_id']}")
            print(f"   å›¾åƒè·¯å¾„: {os.path.abspath(args.image_path)}")
            print(f"   æ¨¡å‹è·¯å¾„: {os.path.abspath(args.model)}")
            print(f"   ä½¿ç”¨è®¾å¤‡: {device}")
    else:
        print("âœ— é¢„æµ‹å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()
