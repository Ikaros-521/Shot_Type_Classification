#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å‡†å¤‡è„šæœ¬
ä»åŸå§‹MovieShotsæ•°æ®é›†å‡†å¤‡è®­ç»ƒæ•°æ®
"""
import os
import sys
import json
import pandas as pd
import cv2
import argparse
import random
from pathlib import Path
from tqdm import tqdm

def parse_json_to_csv(json_path, output_csv):
    """è§£æJSONæ•°æ®åˆ°CSVæ ¼å¼"""
    print(f"ğŸ“– è§£æJSONæ–‡ä»¶: {json_path}")
    
    df = pd.DataFrame()
    i = 0
    
    with open(json_path, 'r', encoding='utf-8') as f:
        while True:
            line = f.readline()
            if not line:
                print(f"âœ“ è§£æå®Œæˆï¼Œå…±å¤„ç† {i} ä¸ªæ–‡ä»¶å¤¹")
                break
            
            # æŸ¥æ‰¾æ–‡ä»¶å¤¹æ ‡è¯†
            if "tt" in line:
                i += 1
                folder_name = line.translate({ord(c): None for c in '\\n\'\" :\{\}\n'})
                
                # æŸ¥æ‰¾æ–‡ä»¶
                line = f.readline()
                while "tt" not in line:
                    if "\"00" in line:
                        file_name = line.translate({ord(c): None for c in '\\n\'\" :\{\}\n'})
                        line = f.readline()
                        label = line.replace('\"label": ', '')
                        label = label.translate({ord(c): None for c in '\\n\'\" :\{\}\n\,'})
                        
                        df = df.append({
                            'Folder': folder_name, 
                            'FileName': file_name, 
                            'Label': label
                        }, ignore_index=True)
                    
                    line = f.readline()
                    if not line:
                        break
    
    # ä¿å­˜CSV
    df.to_csv(output_csv, index=False)
    print(f"âœ“ æ•°æ®å·²ä¿å­˜åˆ°: {output_csv}")
    print(f"ğŸ“Š æ€»è®¡ {len(df)} ä¸ªæ•°æ®æ ·æœ¬")
    
    # æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ
    print("\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
    label_counts = df['Label'].value_counts()
    for label, count in label_counts.items():
        print(f"  {label}: {count}")
    
    return df

def organize_videos(df, source_dir, target_dir):
    """ç»„ç»‡è§†é¢‘æ–‡ä»¶åˆ°åˆ†ç±»æ–‡ä»¶å¤¹"""
    print(f"ğŸ¬ ç»„ç»‡è§†é¢‘æ–‡ä»¶...")
    print(f"æºç›®å½•: {source_dir}")
    print(f"ç›®æ ‡ç›®å½•: {target_dir}")
    
    # åˆ›å»ºç›®æ ‡ç›®å½•
    labels = ['CS', 'ECS', 'FS', 'LS', 'MS']
    for label in labels:
        label_dir = os.path.join(target_dir, label)
        os.makedirs(label_dir, exist_ok=True)
    
    moved_count = 0
    missing_count = 0
    
    for index, row in tqdm(df.iterrows(), total=len(df), desc="å¤„ç†è§†é¢‘æ–‡ä»¶"):
        filename = f'shot_{row["FileName"]}.mp4'
        old_file_path = os.path.join(source_dir, row['Folder'], filename)
        
        if os.path.isfile(old_file_path):
            new_filename = f'{row["Folder"]}_{filename}'
            new_file_path = os.path.join(target_dir, row['Label'], new_filename)
            
            try:
                os.rename(old_file_path, new_file_path)
                moved_count += 1
            except Exception as e:
                print(f"âœ— ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {old_file_path} -> {new_file_path}, é”™è¯¯: {e}")
                missing_count += 1
        else:
            print(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {old_file_path}")
            missing_count += 1
    
    print(f"\nğŸ“Š è§†é¢‘æ–‡ä»¶ç»„ç»‡å®Œæˆ:")
    print(f"  æˆåŠŸç§»åŠ¨: {moved_count}")
    print(f"  ç¼ºå¤±æ–‡ä»¶: {missing_count}")

def extract_frames_from_videos(video_dir, output_dir, frame_interval=25):
    """ä»è§†é¢‘æå–å¸§å›¾åƒ"""
    print(f"ğŸ–¼ï¸  ä»è§†é¢‘æå–å¸§å›¾åƒ...")
    print(f"è§†é¢‘ç›®å½•: {video_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"å¸§é—´éš”: {frame_interval}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    labels = ['CS', 'ECS', 'FS', 'LS', 'MS']
    for label in labels:
        label_dir = os.path.join(output_dir, label)
        os.makedirs(label_dir, exist_ok=True)
    
    total_extracted = 0
    processed_videos = 0
    
    for label in labels:
        video_label_dir = os.path.join(video_dir, label)
        if not os.path.exists(video_label_dir):
            print(f"âœ— è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_label_dir}")
            continue
        
        video_files = [f for f in os.listdir(video_label_dir) if f.lower().endswith('.mp4')]
        print(f"\nå¤„ç† {label} ç±»åˆ«ï¼Œå…± {len(video_files)} ä¸ªè§†é¢‘")
        
        for video_file in tqdm(video_files, desc=f"æå–{label}å¸§"):
            video_path = os.path.join(video_label_dir, video_file)
            
            try:
                cap = cv2.VideoCapture(video_path)
                if not cap.isOpened():
                    print(f"âœ— æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
                    continue
                
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                frame_count = 0
                
                for frame_idx in range(0, total_frames, frame_interval):
                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                    ret, frame = cap.read()
                    
                    if ret:
                        output_filename = f"{os.path.splitext(video_file)[0]}_frame_{frame_idx}.jpg"
                        output_path = os.path.join(output_dir, label, output_filename)
                        cv2.imwrite(output_path, frame)
                        frame_count += 1
                
                cap.release()
                total_extracted += frame_count
                processed_videos += 1
                
            except Exception as e:
                print(f"âœ— å¤„ç†è§†é¢‘å¤±è´¥: {video_path}, é”™è¯¯: {e}")
    
    print(f"\nğŸ“Š å¸§æå–å®Œæˆ:")
    print(f"  å¤„ç†è§†é¢‘æ•°: {processed_videos}")
    print(f"  æå–å¸§æ•°: {total_extracted}")

def split_train_test_data(frame_dir, train_dir, test_dir, test_ratio=0.2, random_seed=42):
    """åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†"""
    print(f"ğŸ”€ åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†...")
    print(f"æºç›®å½•: {frame_dir}")
    print(f"è®­ç»ƒé›†ç›®å½•: {train_dir}")
    print(f"æµ‹è¯•é›†ç›®å½•: {test_dir}")
    print(f"æµ‹è¯•é›†æ¯”ä¾‹: {test_ratio}")
    
    # è®¾ç½®éšæœºç§å­
    random.seed(random_seed)
    
    # åˆ›å»ºç›®æ ‡ç›®å½•
    labels = ['CS', 'ECS', 'FS', 'LS', 'MS']
    for label in labels:
        for target_dir in [train_dir, test_dir]:
            label_dir = os.path.join(target_dir, label)
            os.makedirs(label_dir, exist_ok=True)
    
    total_files = 0
    train_files = 0
    test_files = 0
    
    for label in labels:
        source_label_dir = os.path.join(frame_dir, label)
        if not os.path.exists(source_label_dir):
            print(f"âœ— æºç›®å½•ä¸å­˜åœ¨: {source_label_dir}")
            continue
        
        image_files = [f for f in os.listdir(source_label_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        random.shuffle(image_files)
        
        split_index = int(len(image_files) * (1 - test_ratio))
        train_list = image_files[:split_index]
        test_list = image_files[split_index:]
        
        # ç§»åŠ¨è®­ç»ƒæ–‡ä»¶
        for img_file in train_list:
            src = os.path.join(source_label_dir, img_file)
            dst = os.path.join(train_dir, label, img_file)
            try:
                os.rename(src, dst)
                train_files += 1
            except Exception as e:
                print(f"âœ— ç§»åŠ¨è®­ç»ƒæ–‡ä»¶å¤±è´¥: {src} -> {dst}, é”™è¯¯: {e}")
        
        # ç§»åŠ¨æµ‹è¯•æ–‡ä»¶
        for img_file in test_list:
            src = os.path.join(source_label_dir, img_file)
            dst = os.path.join(test_dir, label, img_file)
            try:
                os.rename(src, dst)
                test_files += 1
            except Exception as e:
                print(f"âœ— ç§»åŠ¨æµ‹è¯•æ–‡ä»¶å¤±è´¥: {src} -> {dst}, é”™è¯¯: {e}")
        
        total_files += len(image_files)
        print(f"  {label}: æ€»è®¡ {len(image_files)}, è®­ç»ƒ {len(train_list)}, æµ‹è¯• {len(test_list)}")
    
    print(f"\nğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
    print(f"  æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"  è®­ç»ƒæ–‡ä»¶æ•°: {train_files} ({train_files/total_files*100:.1f}%)")
    print(f"  æµ‹è¯•æ–‡ä»¶æ•°: {test_files} ({test_files/total_files*100:.1f}%)")

def main():
    parser = argparse.ArgumentParser(
        description='MovieShotsæ•°æ®é›†å‡†å¤‡å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å®Œæ•´æµç¨‹
  python prepare_data.py --data-dir ./data --full-process
  
  # ä»…è§£æJSONåˆ°CSV
  python prepare_data.py --data-dir ./data --parse-json
  
  # ä»…ç»„ç»‡è§†é¢‘æ–‡ä»¶
  python prepare_data.py --data-dir ./data --organize-videos
  
  # ä»…æå–è§†é¢‘å¸§
  python prepare_data.py --data-dir ./data --extract-frames --frame-interval 30
  
  # ä»…åˆ†å‰²æ•°æ®é›†
  python prepare_data.py --data-dir ./data --split-data --test-ratio 0.3
        """
    )
    
    parser.add_argument('--data-dir',
                       default='./data',
                       help='æ•°æ®æ ¹ç›®å½• (é»˜è®¤: ./data)')
    
    parser.add_argument('--full-process',
                       action='store_true',
                       help='æ‰§è¡Œå®Œæ•´çš„æ•°æ®å‡†å¤‡æµç¨‹')
    
    parser.add_argument('--parse-json',
                       action='store_true',
                       help='è§£æJSONåˆ°CSV')
    
    parser.add_argument('--organize-videos',
                       action='store_true',
                       help='ç»„ç»‡è§†é¢‘æ–‡ä»¶')
    
    parser.add_argument('--extract-frames',
                       action='store_true',
                       help='ä»è§†é¢‘æå–å¸§')
    
    parser.add_argument('--split-data',
                       action='store_true',
                       help='åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†')
    
    parser.add_argument('--frame-interval',
                       type=int,
                       default=25,
                       help='è§†é¢‘å¸§æå–é—´éš” (é»˜è®¤: 25)')
    
    parser.add_argument('--test-ratio',
                       type=float,
                       default=0.2,
                       help='æµ‹è¯•é›†æ¯”ä¾‹ (é»˜è®¤: 0.2)')
    
    args = parser.parse_args()
    
    # è®¾ç½®è·¯å¾„
    json_path = os.path.join(args.data_dir, 'v1_full_trailer.json')
    csv_path = os.path.join(args.data_dir, 'dataset.csv')
    trailer_dir = os.path.join(args.data_dir, 'trailer')
    categorized_dir = os.path.join(args.data_dir, 'categorized')
    frames_dir = os.path.join(args.data_dir, 'frames')
    train_dir = os.path.join(args.data_dir, 'frames', 'training')
    test_dir = os.path.join(args.data_dir, 'frames', 'testing')
    
    print("ğŸš€ MovieShotsæ•°æ®é›†å‡†å¤‡å·¥å…·")
    print("=" * 50)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå…·ä½“æ­¥éª¤ï¼Œæ‰§è¡Œå®Œæ•´æµç¨‹
    if not any([args.parse_json, args.organize_videos, args.extract_frames, args.split_data]):
        args.full_process = True
    
    try:
        # æ­¥éª¤1: è§£æJSONåˆ°CSV
        if args.full_process or args.parse_json:
            if not os.path.exists(json_path):
                print(f"âœ— JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
                print("è¯·ç¡®ä¿å·²ä¸‹è½½MovieShotsæ•°æ®é›†å¹¶å°†v1_full_trailer.jsonæ”¾åœ¨dataç›®å½•ä¸­")
                sys.exit(1)
            
            df = parse_json_to_csv(json_path, csv_path)
        
        # æ­¥éª¤2: ç»„ç»‡è§†é¢‘æ–‡ä»¶
        if args.full_process or args.organize_videos:
            if 'df' not in locals():
                df = pd.read_csv(csv_path)
            
            if not os.path.exists(trailer_dir):
                print(f"âœ— è§†é¢‘æºç›®å½•ä¸å­˜åœ¨: {trailer_dir}")
                print("è¯·ç¡®ä¿å·²ä¸‹è½½MovieShotsæ•°æ®é›†çš„è§†é¢‘æ–‡ä»¶")
                sys.exit(1)
            
            organize_videos(df, trailer_dir, categorized_dir)
        
        # æ­¥éª¤3: æå–è§†é¢‘å¸§
        if args.full_process or args.extract_frames:
            if not os.path.exists(categorized_dir):
                print(f"âœ— åˆ†ç±»è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {categorized_dir}")
                print("è¯·å…ˆæ‰§è¡Œè§†é¢‘ç»„ç»‡æ­¥éª¤")
                sys.exit(1)
            
            extract_frames_from_videos(categorized_dir, frames_dir, args.frame_interval)
        
        # æ­¥éª¤4: åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        if args.full_process or args.split_data:
            if not os.path.exists(frames_dir):
                print(f"âœ— å¸§å›¾åƒç›®å½•ä¸å­˜åœ¨: {frames_dir}")
                print("è¯·å…ˆæ‰§è¡Œå¸§æå–æ­¥éª¤")
                sys.exit(1)
            
            split_train_test_data(frames_dir, train_dir, test_dir, args.test_ratio)
        
        print("\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆï¼")
        print("\nğŸ“ ç”Ÿæˆçš„ç›®å½•ç»“æ„:")
        print(f"{args.data_dir}/")
        print("â”œâ”€â”€ dataset.csv                    # æ•°æ®æ ‡ç­¾æ–‡ä»¶")
        print("â”œâ”€â”€ categorized/                   # åˆ†ç±»åçš„è§†é¢‘æ–‡ä»¶")
        print("â”‚   â”œâ”€â”€ CS/")
        print("â”‚   â”œâ”€â”€ ECS/")
        print("â”‚   â”œâ”€â”€ FS/")
        print("â”‚   â”œâ”€â”€ LS/")
        print("â”‚   â””â”€â”€ MS/")
        print("â””â”€â”€ frames/                       # æå–çš„å¸§å›¾åƒ")
        print("    â”œâ”€â”€ training/                 # è®­ç»ƒé›†")
        print("    â”‚   â”œâ”€â”€ CS/")
        print("    â”‚   â”œâ”€â”€ ECS/")
        print("    â”‚   â”œâ”€â”€ FS/")
        print("    â”‚   â”œâ”€â”€ LS/")
        print("    â”‚   â””â”€â”€ MS/")
        print("    â””â”€â”€ testing/                  # æµ‹è¯•é›†")
        print("        â”œâ”€â”€ CS/")
        print("        â”œâ”€â”€ ECS/")
        print("        â”œâ”€â”€ FS/")
        print("        â”œâ”€â”€ LS/")
        print("        â””â”€â”€ MS/")
        
        print(f"\nğŸ¯ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®­ç»ƒæ¨¡å‹:")
        print(f"python train.py --data-dir {train_dir}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâœ— å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
