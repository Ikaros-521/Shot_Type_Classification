#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡é•œå¤´ç±»å‹åˆ†ç±»é¢„æµ‹è„šæœ¬
å¯¹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒè¿›è¡Œæ‰¹é‡é¢„æµ‹
"""
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import argparse
import os
import sys
import glob
import json
from datetime import datetime

# å¯¼å…¥å•å¼ é¢„æµ‹çš„å‡½æ•°
from predict import load_model, preprocess_image, predict, CLASS_MAPPING

def batch_predict(input_dir, output_file, model, device, verbose=False):
    """æ‰¹é‡é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒ"""
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']
    
    # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = []
    for ext in image_extensions:
        image_files.extend(glob.glob(os.path.join(input_dir, ext)))
        image_files.extend(glob.glob(os.path.join(input_dir, ext.upper())))
    
    if not image_files:
        print(f"âœ— åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return []
    
    print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    results = []
    processed = 0
    failed = 0
    
    for image_path in image_files:
        try:
            if verbose:
                print(f"æ­£åœ¨å¤„ç†: {os.path.basename(image_path)}")
            
            result = predict(image_path, model, device)
            if result:
                result['image_path'] = image_path
                result['filename'] = os.path.basename(image_path)
                results.append(result)
                processed += 1
                
                if verbose:
                    print(f"  âœ“ {result['class_name']} ({result['confidence']:.3f})")
            else:
                failed += 1
                print(f"  âœ— é¢„æµ‹å¤±è´¥")
                
        except Exception as e:
            failed += 1
            print(f"  âœ— å¤„ç†å¤±è´¥: {e}")
    
    print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
    print(f"   æ€»è®¡: {len(image_files)} ä¸ªæ–‡ä»¶")
    print(f"   æˆåŠŸ: {processed} ä¸ª")
    print(f"   å¤±è´¥: {failed} ä¸ª")
    
    # ä¿å­˜ç»“æœ
    if results:
        save_results(results, output_file)
    
    return results

def save_results(results, output_file):
    """ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ–‡ä»¶"""
    
    # å‡†å¤‡è¾“å‡ºæ•°æ®
    output_data = {
        'timestamp': datetime.now().isoformat(),
        'total_images': len(results),
        'class_distribution': {},
        'results': results
    }
    
    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    for result in results:
        class_name = result['class_name']
        if class_name not in output_data['class_distribution']:
            output_data['class_distribution'][class_name] = 0
        output_data['class_distribution'][class_name] += 1
    
    # ä¿å­˜ä¸ºJSONæ ¼å¼
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âœ— ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    # æ‰“å°ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
    print(f"\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
    for class_name, count in output_data['class_distribution'].items():
        percentage = (count / len(results)) * 100
        print(f"   {class_name}: {count} ({percentage:.1f}%)")

def main():
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡é•œå¤´ç±»å‹åˆ†ç±»é¢„æµ‹å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python batch_predict.py ./images                     # é¢„æµ‹imagesæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒ
  python batch_predict.py ./images --output results.json  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python batch_predict.py ./images --verbose           # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
    )
    
    parser.add_argument('input_dir', 
                       help='è¾“å…¥å›¾åƒç›®å½•è·¯å¾„')
    parser.add_argument('--output', '-o',
                       default='prediction_results.json',
                       help='è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„ (é»˜è®¤: prediction_results.json)')
    parser.add_argument('--model', 
                       default='./models/Pytorch_Classification_50ep.pt',
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./models/Pytorch_Classification_50ep.pt)')
    parser.add_argument('--verbose', '-v',
                       action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.isdir(args.input_dir):
        print(f"âœ— è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        sys.exit(1)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model):
        print(f"âœ— æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        sys.exit(1)
    
    # è®¾ç½®è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    model = load_model(args.model, device)
    
    # æ‰¹é‡é¢„æµ‹
    print(f"å¼€å§‹æ‰¹é‡å¤„ç†ç›®å½•: {args.input_dir}")
    results = batch_predict(args.input_dir, args.output, model, device, args.verbose)

if __name__ == "__main__":
    main()
